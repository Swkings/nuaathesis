\chapter{基于邻域结构迁移的多目标组合优化算法}
\label{chap:NST}

\section{引言}
\label{sec:NST:引言}
很多现实中的问题都是由相互冲突和影响的多个目标组成，并且在给定条件下，问题的多个目标需要同时达到最佳，这类问题被称作多目标优化问题（MOP）。当问题的变量域为有限集合时，这类问题就可以被称为多目标组合优化问题（CMOP）。多目标组合优化问题在现实生活中大量存在，并且在大部分行业都可见，包括但不限于运输、能源、医疗、金融、电力等。由于其变量域所演变出的组合数巨大（NP难），传统的确定性算法难以在合理的时间内给出这类问题的解决方案。因此，设计能够在合理时间内给出近似解决方案的启发式方法，就成了求解多目标组合优化问题的关键。
\par
自多目标组合优化被提出后，研究者们就针对这类问题设计了一系列的多目标组合优化算法，其大多数是基于进化算法，可主要分为三大类：基于Pareto支配关系的多目标优化算法\cite{deb2002fast}、基于指标的多目标优化算法（）和基于分解的多目标优化算法（）。但是，在应对某些高维度的多目标组合优化问题，基于Pareto支配关系和基于指标的多目标进化算法都有着其本身的缺陷处。因为在高维度解集中，包含的几乎都是非支配的解，这就导致了只用Pareto支配关系无法区分这些非支配解的优劣，从而不能够均匀且广泛的选出下一代进化的种群。同样，基于指标的多目标进化算法因其指标算法的高复杂度，使得它们在高维度问题中会耗费大量计算资源。然而，基于分解的多目标进化算法因其分解的策略，使得它们被广泛的应用于多目标组合优化问题中，这使得这种基于分解的方法在过去的十几年中，成为了处理多目标组合优化问题的最突出的方法之一。一个代表性的算法是MOEA/D\cite{zhang2007moea}，其核心思想就是把一个多目标优化问题通过权重向量分解成一组单目标子问题，然后根据各子问题之间的相似度关系构成邻居关系，然后利用邻居子问题之间的信息对所有子问题进行优化。
\par
近年来，利用机器学习中相关的思想来进一步提高多目标优化算法的效率，成为了当下研究的热点。在进化优化的背景下，基于迁移学习（TL）中利用跨问题领域的有用特征数据来提高学习性能这一方法，已经有很多研究者开始将其应用到多目标优化问题当中，并将其与进化算法相结合，提出了进化迁移优化（ETO）\cite{feng2020explicit,lin2020effective,tan2021evolutionary}。在章节~\ref{sec:背景介绍:进化迁移优化}~中可以了解到，在多目标和超多目标优化中的知识信息可以采用非支配解集等形式来实现跨问题的迁移。当ETO与基于分解的多目标进化算法相结合时，分解得来的一系列子问题之间拥有天然的联系，这使得所属子问题的知识能够很好的被迁移到其他子问题上，通过不同子问题之间的相互促进，以此来提高算法的整体效率和质量。
\par
由此，将基于分解的多目标进化算法和进化迁移优化相结合，以此来针对多目标组合优化问题来进行算法设计，是本章研究的重点。由于在ETO中，所使用的知识信息与所求问题密切相关，且本章将使用邻域结构（章节~\ref{subsec:背景介绍:局部搜索:邻域结构}）当做被迁移的知识，为此，本章将使用MOTSP问题（章节~\ref{subsec:背景介绍:测试问题:MOTSP}）来对设计的算法进行性能测试。

\section{研究动机}
\label{sec:NST:研究动机}
从前面的章节可以了解到，基于分解的多目标进化算法是通过将多目标问题分解成一组单目标优化问题，然后对这些单目标问题进行求解，其目的在于将复杂的问题降维，由复杂的多目标问题转变成简单的单目标问题，然后可以用解决单目标问题的方法来求解，最后将这些解组合起来就成为了多目标问题的解集。并且，在基于分解的方法中最具代表性的MOEA/D中使用了“邻居”的概念，MOEA/D根据被分解后的子问题之间的联系，从而形成子问题间的邻居关系，然后利用子问题之间的联系，通过用当前子问题中的优质解来替换其他邻居子问题中的差解，以此达到不同子问题间的协作效应。
\par
当求解的问题的目标数少时，被分解成的一组单目标优化问题之间存在着“邻居”关系，此时邻居子问题之间还能够依靠着协作来达到相互促进的效果。但是，当求解的问题的目标数变多时，如果依照低维问题的分解粒度，则通过分解得到的单目标问题数量是成指数增加的，这就导致了分解空间的爆炸，若使用算法对如此多的子问题进行优化，这将耗费大量计算资源。如果加大分解的粒度来使得分解得到的子问题恒定，那么这些子问题之间的“邻居”关系将会变得极其微弱，就算当前子问题产生了优质解也难以替换其他子问题的解，这就导致算法的协作效应难以发挥作用。
\par
在进化优化的背景下，ETO利用跨问题领域的知识迁移这一特征能够很好地适用于基于分解的多目标进化算法。因此，可以将ETO的思想融入到基于分解的多目标进化算法当中，在分解得到的子问题之间建立知识迁移模型。因此，使用ETO的目的在于挖掘子问题的内在信息，然后通过迁移的方式将这些信息在不同子问题之间传递使用。然而，通过章节~\ref{sec:背景介绍:进化迁移优化}~可知，现在ETO应用到多目标组合优化问题中，大多数是通过将非支配解当做被迁移的信息。然而，通过解迁移的方式，类似于MOEA/D中的协作，如果子问题之间的相似度较低，那么从这些非支配解中能够学习到的有用信息就会很少（解中蕴含的信息本身就少），这些信息很大可能对其他子问题无效，以致产生负迁移，使得难以对问题的优化起到促进作用。
\par
从章节~\ref{subsec:背景介绍:局部搜索:邻域结构}~可以知道，一些组合优化问题可以用邻域结构的方式具现化，这些邻域结构本身就携带了这个问题的大部分特征，并且，邻域结构还能够作为局部搜索算子的一部分。若使用邻域结构来承载子问题的内在信息，容易知道，邻域结构能够承载的信息量要比使用非支配解所蕴含的信息量更多。因此，当以邻域结构作为知识迁移的基本单位，那么就算子问题的相关性变弱，算法也能够从邻域结构中挖掘出一种结构模式，然后使用特定的局部搜索方法来使用该结构，从而促进子问题的优化。
\par
因此，综合章节~\ref{sec:NS_Method:邻域结构生成算法}~提出的邻域结构生成方法，结合基于分解的多目标进化算法和进化迁移优化，本章提出了一种基于邻域结构迁移的多目标组合优化算法（NST-MOEA）。

\section{邻域结构迁移}
\label{sec:NST:邻域结构迁移}

\section{算法框架}
\label{sec:NST:算法框架}

\section{实验与讨论}
\label{sec:NST:实验与讨论}

\section{本章小结}
\label{sec:NST:本章小结}